<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>MLOps repo walkthrough</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">MLOps repo walkthrough</h1>
</header>
<section data-field="subtitle" class="p-summary">
This article walks through a repo that automates model training, testing, and deployment using Github Actions, DVC, and AWS Lambda.
</section>
<section data-field="body" class="e-content">
<section name="6a9b" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="7718" id="7718" class="graf graf--h3 graf--leading graf--title">MLOps repo walkthrough</h3><p name="c2fc" id="c2fc" class="graf graf--p graf-after--h3">There’s a big difference between building a machine learning model that works on your computer, and making that model available for others to use. If implemented poorly, your users will be frustrated that your software isn’t reliable. And it can take months to implement it well!</p><p name="1e04" id="1e04" class="graf graf--p graf-after--p graf--trailing"><a href="https://medium.com/@keith.trnka/mlops-design-principles-e30cc40442a1" data-href="https://medium.com/@keith.trnka/mlops-design-principles-e30cc40442a1" class="markup--anchor markup--p-anchor" target="_blank">My previous article shared the principles I’ve learned over the years</a>. This one walks through example code and critiques the approach. When I started deploying machine learning models into web services I found the complexity bewildering, and I hope this walkthrough will help readers in similar situations.</p></div></div></section><section name="cd47" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="6213" id="6213" class="graf graf--p graf--leading">I built a series of prototypes to explore different tools and ideas in MLOps for a basic text classifier. This post will focus on the most recent prototype. It has automated training, testing, and deployment of models to a web service with AWS Lambda.</p><p name="50df" id="50df" class="graf graf--p graf-after--p">I limited the number of ML-specific tools for two reasons: 1) I wanted to use similar infrastructure to traditional software projects and 2) at work it was often easier to meet compliance needs this way.</p><p name="008c" id="008c" class="graf graf--p graf-after--p"><em class="markup--em markup--p-em">Side note: You may notice that some of these repos are a couple years old. Originally I did these just for myself. Over the years I’ve found that I’ve often used them as examples for others and that’s motivated me to finally write it up.</em></p><h3 name="4bf5" id="4bf5" class="graf graf--h3 graf-after--p">The basics</h3><p name="cd65" id="cd65" class="graf graf--p graf-after--h3">I sometimes miss the old days when you’d host your code on a server under a desk somewhere! In those days, getting our code or models on a server just meant copying files and restarting the web daemon.</p><p name="0caa" id="0caa" class="graf graf--p graf-after--p">There are many issues with that approach though. These are a few of those problems:</p><ul class="postList"><li name="b7fe" id="b7fe" class="graf graf--li graf-after--p">It means we’ll need to spend much more of our time just managing servers, like applying security patches, ensuring that the internet and power don’t go out, or fixing it when a hardware component breaks.</li><li name="5454" id="5454" class="graf graf--li graf-after--li">The process is prone to mistakes and bugs, such as code that works on your computer but not the server. Or you might forget to run tests.</li><li name="a1ce" id="a1ce" class="graf graf--li graf-after--li">The under-desk service can only handle so many requests per second. If your site becomes suddenly popular it may not be able to keep up with the surge of users.</li></ul><p name="a7d6" id="a7d6" class="graf graf--p graf-after--li">Modern tools are designed to address these problems, but they can make it more difficult to learn a new code base.</p><h3 name="f36a" id="f36a" class="graf graf--h3 graf-after--p">Deploying models to Lambda</h3><p name="a4d9" id="a4d9" class="graf graf--p graf-after--h3"><a href="https://github.com/ktrnka/mlops_example_lambda" data-href="https://github.com/ktrnka/mlops_example_lambda" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">This repo</a> has training and serving for a news classification scikit-learn model but it should work for PyTorch and other libraries.</p><p name="bc30" id="bc30" class="graf graf--p graf-after--p">Let’s say hypothetically that we’re building a backend service for Medium to recommend appropriate categories for new posts. The Medium frontend will send the text of the article to our backend and receive the predicted category.</p><p name="c120" id="c120" class="graf graf--p graf-after--p">As I go through the repo I’ll summarize terminology at the end of each section.</p><h4 name="7029" id="7029" class="graf graf--h4 graf-after--p">API Gateway and Lambda</h4><p name="7f43" id="7f43" class="graf graf--p graf-after--h4">The HTTP request is received by API gateway and forwarded to Lambda. If there’s a Lambda worker available, it forwards the request to the worker. If there isn’t, it starts a new worker which will load the code, load the model, and execute the request. If it takes more than 30 seconds to load the code and model, the request will fail but eventually it’ll boot and then requests will work.</p><p name="6c13" id="6c13" class="graf graf--p graf-after--p">For testing I used a POST request with a simple payload like this:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="json" name="f336" id="f336" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-punctuation">{</span><br />    <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;The Seattle Seahawks crushed the Cleveland Browns on Thursday 52-7&quot;</span><br /><span class="hljs-punctuation">}</span></span></pre><p name="d6f0" id="d6f0" class="graf graf--p graf-after--pre">API gateway receives the request and calls our Lambda handler with request info in the parameters.</p><p name="759a" id="759a" class="graf graf--p graf-after--p">In the Lambda code, API gateway sends this information in two dicts <em class="markup--em markup--p-em">event</em> and <em class="markup--em markup--p-em">context. </em>From serving/app/app.py:</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="0603" id="0603" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">def</span> <span class="hljs-title function_">lambda_handler</span>(<span class="hljs-params">event, context</span>):<br />    request_body = json.loads(event[<span class="hljs-string">&quot;body&quot;</span>])<br />    prediction = model.predict([request_body[<span class="hljs-string">&quot;text&quot;</span>]])[<span class="hljs-number">0</span>]<br /><br />    <span class="hljs-keyword">return</span> {<br />        <span class="hljs-string">&quot;statusCode&quot;</span>: <span class="hljs-number">200</span>,<br />        <span class="hljs-string">&quot;body&quot;</span>: json.dumps({<br />            <span class="hljs-string">&quot;response&quot;</span>: prediction,<br />            <span class="hljs-string">&quot;request&quot;</span>: request_body<br />        })<br />    }</span></pre><p name="22da" id="22da" class="graf graf--p graf-after--pre">API gateway sends the POST request body in event[“body”] as a plain string so we need to parse the JSON in it. Then we run the text field through the model. Note that we need to make it into a list of inputs (with one element) and then take the first prediction from the output. That’s because scikit-learn predict methods are designed for batches of data. Then API gateway needs the response in a particular shape dict including the HTTP status code (200). Out of habit, I like to also return the request data to make debugging easier.</p><p name="1f9c" id="1f9c" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">New terminology</strong></p><ul class="postList"><li name="8bef" id="8bef" class="graf graf--li graf-after--p"><a href="https://aws.amazon.com/lambda/" data-href="https://aws.amazon.com/lambda/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">AWS Lambda</a>: This runs our code on a server and handles scaling up the number of workers automatically.</li><li name="4154" id="4154" class="graf graf--li graf-after--li"><a href="https://aws.amazon.com/api-gateway/" data-href="https://aws.amazon.com/api-gateway/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">AWS API Gateway</a>: This serves as a bridge between our Lambda and requests coming from the Internet.</li><li name="4ddc" id="4ddc" class="graf graf--li graf-after--li">HTTP POST: This is the <a href="https://www.restapitutorial.com/lessons/httpmethods.html" data-href="https://www.restapitutorial.com/lessons/httpmethods.html" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">HTTP method</a> that we’re using. Although GET would be a more semantically-appropriate method, sending JSON generally isn’t supported with GET. POST is more common in my experience because the input data structure is often complex.</li></ul><h4 name="9b56" id="9b56" class="graf graf--h4 graf-after--li">Docker and Python, called by Lambda</h4><p name="98d5" id="98d5" class="graf graf--p graf-after--h4">From serving/app/Dockerfile:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="css" name="3159" id="3159" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">CMD <span class="hljs-selector-attr">[<span class="hljs-string">&quot;app.lambda_handler&quot;</span>]</span></span></pre><p name="f793" id="f793" class="graf graf--p graf-after--pre">This is the last line of the Dockerfile, and it tells Lambda to call the lambda_handler function in app.py<em class="markup--em markup--p-em">.</em></p><p name="ab10" id="ab10" class="graf graf--p graf-after--p">When the Lambda starts, it imports the app.py file which causes everything outside of a function to be run, such as loading the model in our case. With Lambdas we call this a cold start. Then it’s available until the worker is shut down. The model is baked into the same Docker image as the code and loaded just like any other file. The Docker image is built and deployed from Github Actions when code is merged to main that changes anything in the <em class="markup--em markup--p-em">serving</em> folder. Likewise, the configuration of API gateway and Lambda can be updated at the same time. One of the files under <em class="markup--em markup--p-em">serving</em> is the model file itself, which is stored using <a href="https://dvc.org/" data-href="https://dvc.org/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">data version control (DVC)</a>. If the model changes when merging to <em class="markup--em markup--p-em">main</em>, the Docker image will be rebuilt and redeployed with the new model.</p><p name="3c6c" id="3c6c" class="graf graf--p graf-after--p">Here’s where the model is loaded in serving/app/app.py with timing and metrics omitted:</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="6fb6" id="6fb6" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_model</span>():<br />    ...<br />    model_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&quot;data/model.joblib.gz&quot;</span>, )<br />    model = joblib.load(model_path)<br /><br />    ...<br /><br />    <span class="hljs-keyword">return</span> model<br /><br />model = load_model()</span></pre><p name="9d1b" id="9d1b" class="graf graf--p graf-after--pre">All we’re doing is calling joblib.load on the file path. This works because the model was saved with joblib and because the serving code has all the dependencies needed for the model from scikit-learn.</p><p name="5625" id="5625" class="graf graf--p graf-after--p">The first line is making sure that the file path is relative to app.py, not relative to where app.py is being run from, because I don’t know if Lambda makes that consistent. I do that out of habit because I’ve been burned in the past when code was run from an unexpected directory.</p><p name="0e95" id="0e95" class="graf graf--p graf-after--p">That model file is baked into the Docker image in serving/app/Dockerfile:</p><pre data-code-block-mode="0" spellcheck="false" name="3dee" id="3dee" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">COPY data ./data</span></pre><p name="9ce5" id="9ce5" class="graf graf--p graf-after--pre">It’s just copying the serving/app/data folder into the Docker image from the machine that’s building the Docker image. If for some reason we needed another model, we’d just put it in that folder and it’d be available inside of Docker too.</p><p name="1a5f" id="1a5f" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">New terms</strong></p><ul class="postList"><li name="c048" id="c048" class="graf graf--li graf-after--p">Cold start: When there are no Lambda workers immediately available, Lambda must start one up.</li><li name="516a" id="516a" class="graf graf--li graf-after--li"><a href="https://www.docker.com/" data-href="https://www.docker.com/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Docker</a>: Docker is a way of packaging code, data, and dependencies together in a way that can be run the same way on any computer.</li><li name="359f" id="359f" class="graf graf--li graf-after--li"><a href="https://dvc.org/" data-href="https://dvc.org/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Data Version Control (DVC)</a>: I use DVC to version large files such as models, because git doesn’t work well with large files.</li><li name="7b3a" id="7b3a" class="graf graf--li graf-after--li"><a href="https://github.com/features/actions" data-href="https://github.com/features/actions" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Github Actions</a>: Github that will run our code on their servers for a short time, triggered by changes in Github or on a timer. It’s free for small-scale usage.</li><li name="e066" id="e066" class="graf graf--li graf-after--li">main branch: In Github development, it’s common to put the current version of code in a branch named “main” and create other branches while writing new code.</li><li name="345d" id="345d" class="graf graf--li graf-after--li">merged: When changes from one git branch are included into another branch. In this case, I’m talking about merging code from a development branch into the main branch.</li></ul><p name="d1fd" id="d1fd" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Additional reading</strong></p><ul class="postList"><li name="c04b" id="c04b" class="graf graf--li graf-after--p"><a href="https://aws.amazon.com/blogs/compute/operating-lambda-performance-optimization-part-1/" data-href="https://aws.amazon.com/blogs/compute/operating-lambda-performance-optimization-part-1/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Operating Lambda: Performance optimization — Part 1 (AWS)</a>: This covers cold starts and how to address them.</li><li name="fa1f" id="fa1f" class="graf graf--li graf-after--li"><a href="https://docs.docker.com/get-started/overview/" data-href="https://docs.docker.com/get-started/overview/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Docker overview (Docker)</a></li><li name="2817" id="2817" class="graf graf--li graf-after--li"><a href="https://aws.amazon.com/docker/" data-href="https://aws.amazon.com/docker/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">What is Docker? (AWS)</a></li></ul><h4 name="e436" id="e436" class="graf graf--h4 graf-after--li">Building and deploying with CDK from Github Actions</h4><p name="6d8e" id="6d8e" class="graf graf--p graf-after--h4">The Docker image is built and uploaded to AWS Elastic Container Registry (ECR) in CDK in serving/deployment/stacks/lambda_service.py:</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="0275" id="0275" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">handler = lambda_.DockerImageFunction(<br />    self,<br />    <span class="hljs-string">&quot;ExampleTextClassifierHandler&quot;</span>,<br />    code=lambda_.DockerImageCode.from_image_asset(<span class="hljs-string">&quot;../app&quot;</span>),<br />    timeout=cdk.Duration.seconds(<span class="hljs-number">60</span>),<br />    memory_size=<span class="hljs-number">3008</span><br />)</span></pre><p name="1687" id="1687" class="graf graf--p graf-after--pre">The <em class="markup--em markup--p-em">from_image_asset</em> function builds the Docker image for us, which takes as a parameter a directory containing the <em class="markup--em markup--p-em">Dockerfile</em> you want to build. I’m setting the memory size to 3 GB which is probably more than strictly needed but it’ll help with latency because Lambda scales the CPU with more RAM. The 60-second timeout is at the Lambda layer. Keep in mind that API gateway has an <em class="markup--em markup--p-em">independent timeout</em> with a maximum of 30 seconds.</p><p name="37c2" id="37c2" class="graf graf--p graf-after--p">The Docker image is necessary with Lambda due to the model size and the Python dependency size. Otherwise I would’ve used Lambda’s zip-file deployment which is faster.</p><p name="c252" id="c252" class="graf graf--p graf-after--p">CDK is a framework for infrastructure as code (IaC). This means that we’re defining our AWS configuration in code. It helps us standardize configuration and deployments which helps reduce accidents. Because it’s stored in the repo, it also means that we can use the pull request process to have peer review for our configuration. It also means that we’re updating our service code and infrastructure at the same time, so we can bundle together a new model with increased memory for example. And it also means that we can revert configuration changes more easily. Also, as one final benefit, CDK is implemented so that most deployments are done with little or no downtime.</p><p name="5c63" id="5c63" class="graf graf--p graf-after--p">The CDK stack is run from .github/workflows/deploy_service.yml:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="yaml" name="d13b" id="d13b" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">    <span class="hljs-bullet">-</span> <span class="hljs-attr">run:</span> <span class="hljs-string">cdk</span> <span class="hljs-string">deploy</span> <span class="hljs-string">--require-approval</span> <span class="hljs-string">never</span><br />      <span class="hljs-attr">env:</span><br />        <span class="hljs-attr">AWS_ACCESS_KEY_ID:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.AWS_ACCESS_KEY_ID</span> <span class="hljs-string">}}</span><br />        <span class="hljs-attr">AWS_SECRET_ACCESS_KEY:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.AWS_SECRET_ACCESS_KEY</span> <span class="hljs-string">}}</span><br />        <span class="hljs-attr">AWS_DEFAULT_REGION:</span> <span class="hljs-string">us-west-2</span></span></pre><p name="7c5e" id="7c5e" class="graf graf--p graf-after--pre">This runs <em class="markup--em markup--p-em">cdk deploy. </em>We have to turn off interactive approval questions otherwise it’ll hang. The other parts are setting environment variables for the AWS IAM user, copied from the Github Actions Secrets set on this repo (I set those manually). Then when CDK creates your API gateway it’ll show the auto-generated URL in Github Actions.</p><p name="31b2" id="31b2" class="graf graf--p graf-after--p">Further up in deploy_service.yaml, we install DVC and fetch the model:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="yaml" name="3c47" id="3c47" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">    <span class="hljs-bullet">-</span> <span class="hljs-attr">run:</span> <span class="hljs-string">pip</span> <span class="hljs-string">install</span> <span class="hljs-string">dvc[s3]</span><br />    <span class="hljs-bullet">-</span> <span class="hljs-attr">run:</span> <span class="hljs-string">dvc</span> <span class="hljs-string">pull</span><br />      <span class="hljs-attr">env:</span><br />        <span class="hljs-attr">AWS_ACCESS_KEY_ID:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.AWS_ACCESS_KEY_ID</span> <span class="hljs-string">}}</span><br />        <span class="hljs-attr">AWS_SECRET_ACCESS_KEY:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.AWS_SECRET_ACCESS_KEY</span> <span class="hljs-string">}}</span></span></pre><p name="9aa1" id="9aa1" class="graf graf--p graf-after--pre">This also needs AWS credentials to read from the S3 bucket.</p><p name="5110" id="5110" class="graf graf--p graf-after--p">At the very top of the file, we can see when the Github Action workflow is triggered:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="yaml" name="e2ca" id="e2ca" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-attr">on:</span><br />  <span class="hljs-attr">push:</span><br />    <span class="hljs-attr">branches:</span><br />      <span class="hljs-bullet">-</span> <span class="hljs-string">main</span><br />    <span class="hljs-attr">paths:</span><br />    <span class="hljs-bullet">-</span> <span class="hljs-string">&#x27;serving/**&#x27;</span><br />    <span class="hljs-bullet">-</span> <span class="hljs-string">&#x27;.github/workflows/deploy_service.yml&#x27;</span></span></pre><p name="3bda" id="3bda" class="graf graf--p graf-after--pre">This runs the deploy_service.yaml action when <em class="markup--em markup--p-em">main </em>is updated (which happens on PR merge) AND when anything under serving/ is changed, or deploy_service.yaml itself is changed.</p><p name="68a7" id="68a7" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">New terms</strong></p><ul class="postList"><li name="65bc" id="65bc" class="graf graf--li graf-after--p"><a href="https://aws.amazon.com/ecr/" data-href="https://aws.amazon.com/ecr/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">AWS Elastic Container Registry (ECR)</a>: The place to upload Docker images in AWS to be used in Lambda and other AWS services.</li><li name="f72d" id="f72d" class="graf graf--li graf-after--li">Infrastructure as code (IaC): Defining your infrastructure with code rather than clicking buttons in a user interface.</li><li name="ef08" id="ef08" class="graf graf--li graf-after--li"><a href="https://aws.amazon.com/cdk/" data-href="https://aws.amazon.com/cdk/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">AWS Cloud Development Kit (CDK)</a>: AWS tools and libraries for infrastructure as code that can be defined in Javascript or Python.</li><li name="4f02" id="4f02" class="graf graf--li graf-after--li"><a href="https://aws.amazon.com/s3/" data-href="https://aws.amazon.com/s3/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">AWS S3</a>: File storage in AWS.</li><li name="ceac" id="ceac" class="graf graf--li graf-after--li"><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users.html" data-href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users.html" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">AWS IAM user</a>: An account for a computer or person that can take action in your AWS account according to the associated permissions. Typically accessed via an access key and secret. The access key and secret are analogous to a username and password but for programmatic access.</li><li name="8630" id="8630" class="graf graf--li graf-after--li"><a href="https://docs.github.com/en/actions/security-guides/encrypted-secrets" data-href="https://docs.github.com/en/actions/security-guides/encrypted-secrets" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Github Actions Secrets</a>: Sensitive configuration that is stored on Github associated with a repo, and available to the Github Action, such as an access key or password.</li><li name="a35e" id="a35e" class="graf graf--li graf-after--li">Github Action workflow: A series of steps for Github Actions to run, associated with a trigger like a branch change. There’s one yaml file per workflow.</li><li name="0243" id="0243" class="graf graf--li graf-after--li"><a href="https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests" data-href="https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Pull request (PR)</a>: In Github, it’s common to do development on a new branch, then submit a pull request (PR) which is a request to merge the code into another branch (typically main). It’s common for a peer to review the modified code in the PR before approving or requesting changes. It’s also common for companies to restrict their Github repos so that pull requests cannot be merged until someone has approved it.</li></ul><p name="c016" id="c016" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Additional reading</strong></p><ul class="postList"><li name="73bf" id="73bf" class="graf graf--li graf-after--p"><a href="https://spacelift.io/blog/business-benefits-of-iac" data-href="https://spacelift.io/blog/business-benefits-of-iac" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Business Benefits of Infrastructure as Code (Spacelift, 2021)</a></li><li name="e147" id="e147" class="graf graf--li graf-after--li"><a href="https://www.simplilearn.com/tutorials/aws-tutorial/aws-iam" data-href="https://www.simplilearn.com/tutorials/aws-tutorial/aws-iam" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">AWS IAM: Working, Components, and Features Explained (simplilearn, 2022)</a></li></ul><h4 name="95c5" id="95c5" class="graf graf--h4 graf-after--li">Automated service testing run from Github Actions</h4><p name="94a4" id="94a4" class="graf graf--p graf-after--h4">We don’t want to deploy bad code, so we also have automated testing.</p><p name="8685" id="8685" class="graf graf--p graf-after--p">The tests I have are very basic: 1) Test that the endpoint can run without crashing 2) Test that the endpoint crashes as expected if the input text is missing. Those are in serving/tests/test_lambda_handler.py:</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="8594" id="8594" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">class</span> <span class="hljs-title class_">BasicTests</span>(unittest.TestCase):<br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_basic_path</span>(<span class="hljs-params">self</span>):<br />        lambda_handler({<span class="hljs-string">&quot;body&quot;</span>: json.dumps({<span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;example input&quot;</span>})}, <span class="hljs-literal">None</span>)<br /><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_crash</span>(<span class="hljs-params">self</span>):<br />        self.assertRaises(BaseException, lambda_handler, {<span class="hljs-string">&quot;body&quot;</span>: json.dumps({<span class="hljs-string">&quot;not_the_right_one&quot;</span>: <span class="hljs-string">&quot;example input&quot;</span>})}, <span class="hljs-literal">None</span>)</span></pre><p name="2a92" id="2a92" class="graf graf--p graf-after--pre">In these tests I’m calling the lambda_handler directly without the <em class="markup--em markup--p-em">context</em> set, because the function doesn’t use it anyway.</p><p name="cb9b" id="cb9b" class="graf graf--p graf-after--p">They’re triggered from .github/workflows/test_service.yml:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="yaml" name="fd55" id="fd55" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Run</span> <span class="hljs-string">tests</span><br />        <span class="hljs-attr">run:</span> <span class="hljs-string">make</span> <span class="hljs-string">test-service</span></span></pre><p name="bcb0" id="bcb0" class="graf graf--p graf--startsWithDoubleQuote graf-after--pre">“make test-service” is defined in Makefile at the root of the repo:</p><pre data-code-block-mode="0" spellcheck="false" name="1212" id="1212" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">test-service:<br>   PYTHONPATH=serving/app/ python serving/tests/test_lambda_handler.py</span></pre><p name="0d9f" id="0d9f" class="graf graf--p graf-after--pre">This just runs the python command to run the tests and ensures that the app code can be imported into the test code. It’s not strictly needed to have a Makefile rule for it, but I like to do that so that I’m running the exact same test command everywhere: Both in Github Actions for automated testing and also on my computer for local testing.</p><p name="9e8c" id="9e8c" class="graf graf--p graf-after--p">The Github Action is triggered at the top of test_service.yml:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="yaml" name="b41b" id="b41b" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-attr">on:</span><br />  <span class="hljs-attr">push:</span><br />    <span class="hljs-attr">branches-ignore:</span><br />      <span class="hljs-bullet">-</span> <span class="hljs-string">main</span><br />    <span class="hljs-attr">paths:</span><br />    <span class="hljs-bullet">-</span> <span class="hljs-string">&#x27;serving/**&#x27;</span><br />    <span class="hljs-bullet">-</span> <span class="hljs-string">&#x27;.github/workflows/test_service.yml&#x27;</span></span></pre><p name="6172" id="6172" class="graf graf--p graf-after--pre">This translates to “run this action anytime code is pushed to a branch except main, that has a change under serving or a chance to test_service.yml”. This will run on pull requests and also non-PR branches. Github is configured so that if the tests fail, it’ll block any PRs for that branch.</p><p name="31b5" id="31b5" class="graf graf--p graf-after--p">Tests are run if anything under <em class="markup--em markup--p-em">serving</em> changes in a pull request. That includes changes to the model file!</p><h4 name="55c5" id="55c5" class="graf graf--h4 graf-after--p">Re-training the model from Github Actions</h4><p name="4152" id="4152" class="graf graf--p graf-after--h4">Now let’s look at how the model is trained. The key parts of training are in training/src/main.py:</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="5a36" id="5a36" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">model = make_pipeline(<br />    TfidfVectorizer(min_df=<span class="hljs-number">30</span>, ngram_range=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>), sublinear_tf=<span class="hljs-literal">True</span>),<br />    LogisticRegressionCV()<br />)<br /><br />model.fit(training_data.data, training_data.target)<br /><br />joblib.dump(model, os.path.join(args.output_dir, <span class="hljs-string">&quot;model.joblib.gz&quot;</span>), compress=<span class="hljs-number">9</span>)</span></pre><p name="feb5" id="feb5" class="graf graf--p graf-after--pre">This is a bigram model using logistic regression with cross-validation to optimize the regularization weight. The min_df setting ignores infrequent ngrams which helps us keep the model small-ish without losing much accuracy. Sublinear_tf reduces the impact of repetitions of the same ngram, and I find that makes models slightly more robust against weird input.</p><p name="e891" id="e891" class="graf graf--p graf-after--p">I’m using the make_pipeline helper from scikit-learn to build the Pipeline object. I find that scikit-learn pipelines 1) make loading and saving easier 2) make hyperparameter tuning more effective 3) reduce accidental leaks of testing data into training.</p><p name="555e" id="555e" class="graf graf--p graf-after--p">If you look at main.py you’ll also see evaluation of the model and comparison against a baseline as well.</p><p name="81c6" id="81c6" class="graf graf--p graf-after--p">main.py is called from the Makefile from a DVC command:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="makefile" name="0e62" id="0e62" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-section">train:</span><br />   dvc repro train</span></pre><p name="4df6" id="4df6" class="graf graf--p graf-after--pre">As before, I like to use Makefile to ensure that I’m running the same commands on my local machine and on the server. In this example, it’s calling DVC to reproduce the “train” pipeline, which is defined in dvc.yaml:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="yaml" name="60de" id="60de" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-attr">stages:</span><br />  <span class="hljs-attr">train:</span><br />    <span class="hljs-attr">cmd:</span> <span class="hljs-string">python</span> <span class="hljs-string">training/src/main.py</span> <span class="hljs-string">serving/app/data/</span> <span class="hljs-string">serving/app/requirements.txt</span><br />    <span class="hljs-attr">deps:</span><br />    <span class="hljs-bullet">-</span> <span class="hljs-string">training/</span><br />    <span class="hljs-attr">outs:</span><br />    <span class="hljs-bullet">-</span> <span class="hljs-string">serving/app/data/model.joblib.gz</span><br />    <span class="hljs-attr">metrics:</span><br />    <span class="hljs-bullet">-</span> <span class="hljs-string">serving/app/data/metrics.json</span></span></pre><p name="5cea" id="5cea" class="graf graf--p graf-after--pre">This is the <a href="https://dvc.org/doc/start/data-management/data-pipelines" data-href="https://dvc.org/doc/start/data-management/data-pipelines" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">pipeline feature of DVC</a> and it’s similar to <em class="markup--em markup--p-em">make</em> except that it also automatically runs <em class="markup--em markup--p-em">dvc add</em> on our output files to ensure that they’re pushed to S3 on <em class="markup--em markup--p-em">dvc push</em>. The metrics part saves metrics in the specified file and the repro command will show the updated values to us.</p><p name="3425" id="3425" class="graf graf--p graf-after--p">Training is triggered from Github Actions in .github/workflows/train_model.yml:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="yaml" name="f853" id="f853" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-comment"># build when a branch other than main changes training or this file:</span><br /><span class="hljs-attr">on:</span><br />  <span class="hljs-attr">push:</span><br />    <span class="hljs-attr">branches-ignore:</span><br />      <span class="hljs-bullet">-</span> <span class="hljs-string">main</span><br />    <span class="hljs-attr">paths:</span><br />    <span class="hljs-bullet">-</span> <span class="hljs-string">&#x27;training/**&#x27;</span><br />    <span class="hljs-bullet">-</span> <span class="hljs-string">&#x27;.github/workflows/train_model.yml&#x27;</span><br /><br /><span class="hljs-attr">jobs:</span><br />  <span class="hljs-attr">train:</span><br />    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span><br />    <span class="hljs-attr">steps:</span><br />      <span class="hljs-comment"># ... for full steps see github ...</span><br />      <span class="hljs-comment"># train the model</span><br />      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Train</span> <span class="hljs-string">model</span><br />        <span class="hljs-attr">run:</span> <span class="hljs-string">make</span> <span class="hljs-string">train</span><br />      <span class="hljs-comment"># run the web service tests to make sure it still works!</span><br />      <span class="hljs-bullet">-</span> <span class="hljs-attr">run:</span> <span class="hljs-string">pip</span> <span class="hljs-string">install</span> <span class="hljs-string">-r</span> <span class="hljs-string">serving/app/requirements.txt</span><br />      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Run</span> <span class="hljs-string">web</span> <span class="hljs-string">service</span> <span class="hljs-string">tests</span><br />        <span class="hljs-attr">run:</span> <span class="hljs-string">make</span> <span class="hljs-string">test-service</span><br />      <span class="hljs-comment"># commit the model, which needs the IAM user to access S3 on dvc push</span><br />      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Commit</span> <span class="hljs-string">model</span><br />        <span class="hljs-comment"># email address from https://github.community/t/github-actions-bot-email-address/17204/5</span><br />        <span class="hljs-attr">run:</span> <span class="hljs-string">|<br />          git config --local user.email &quot;41898282+github-actions[bot]@users.noreply.github.com&quot;<br />          git config --local user.name &quot;github-actions[bot]&quot;<br />          git commit -am &quot;Automated model build&quot;<br />          dvc push<br />          git push<br /></span>        <span class="hljs-attr">env:</span><br />          <span class="hljs-attr">AWS_ACCESS_KEY_ID:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.AWS_ACCESS_KEY_ID</span> <span class="hljs-string">}}</span><br />          <span class="hljs-attr">AWS_SECRET_ACCESS_KEY:</span> <span class="hljs-string">${{</span> <span class="hljs-string">secrets.AWS_SECRET_ACCESS_KEY</span> <span class="hljs-string">}}</span></span></pre><p name="3d95" id="3d95" class="graf graf--p graf-after--pre">In this example I commented inline and cut some boilerplate code. I’m running the web service tests <em class="markup--em markup--p-em">before</em> committing the model to the repo because 1) This action can’t trigger the test_service action and 2) I don’t want to commit models that fail the tests.</p><h4 name="3547" id="3547" class="graf graf--h4 graf-after--p">Configuring AWS for DVC and Github Actions</h4><p name="05ae" id="05ae" class="graf graf--p graf-after--h4">I setup DVC to use an S3 bucket for storage, which is managed by the Terraform code under <em class="markup--em markup--p-em">infrastructure</em>. It creates the S3 bucket for DVC to use as well as an IAM user for Github Actions to use to access DVC and deploy CDK.</p><p name="0db3" id="0db3" class="graf graf--p graf-after--p">The code is verbose in parts but I’ll give an overview of infrastructure/resources.tf with comments added:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="kotlin" name="2deb" id="2deb" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-comment">// create the bucket. In this file it&#x27;s referenced as aws_s3_bucket.b.bucket</span><br />resource <span class="hljs-string">&quot;aws_s3_bucket&quot;</span> <span class="hljs-string">&quot;b&quot;</span> {<br />  bucket_prefix = <span class="hljs-string">&quot;trnka-dvc-&quot;</span><br />  acl = <span class="hljs-string">&quot;private&quot;</span><br />}<br /><br /><span class="hljs-comment">// create the IAM user for Github Actions to use</span><br />resource <span class="hljs-string">&quot;aws_iam_user&quot;</span> <span class="hljs-string">&quot;github_actions&quot;</span> {<br />  name = <span class="hljs-string">&quot;github_actions_lambda_ml&quot;</span><br />  force_destroy = <span class="hljs-literal">true</span><br />}<br /><br /><span class="hljs-comment">// give the IAM user permissions to list files in the bucket and read/write/delete files</span><br />resource <span class="hljs-string">&quot;aws_iam_user_policy&quot;</span> <span class="hljs-string">&quot;dvc_policy&quot;</span> {<br />  name = <span class="hljs-string">&quot;dvc_policy&quot;</span><br />  user = aws_iam_user.github_actions.name<br /><br />  policy = &lt;&lt;EOF<br />{<br />  <span class="hljs-string">&quot;Version&quot;</span>: <span class="hljs-string">&quot;2012-10-17&quot;</span>,<br />  <span class="hljs-string">&quot;Statement&quot;</span>: [<br />    {<br />      <span class="hljs-string">&quot;Effect&quot;</span>: <span class="hljs-string">&quot;Allow&quot;</span>,<br />      <span class="hljs-string">&quot;Action&quot;</span>: [<span class="hljs-string">&quot;s3:ListBucket&quot;</span>],<br />      <span class="hljs-string">&quot;Resource&quot;</span>: [<span class="hljs-string">&quot;arn:aws:s3:::<span class="hljs-subst">${aws_s3_bucket.b.bucket}</span>&quot;</span>]<br />    },<br />    {<br />      <span class="hljs-string">&quot;Effect&quot;</span>: <span class="hljs-string">&quot;Allow&quot;</span>,<br />      <span class="hljs-string">&quot;Action&quot;</span>: [<br />        <span class="hljs-string">&quot;s3:PutObject&quot;</span>,<br />        <span class="hljs-string">&quot;s3:GetObject&quot;</span>,<br />        <span class="hljs-string">&quot;s3:DeleteObject&quot;</span><br />      ],<br />      <span class="hljs-string">&quot;Resource&quot;</span>: [<span class="hljs-string">&quot;arn:aws:s3:::<span class="hljs-subst">${aws_s3_bucket.b.bucket}</span>/*&quot;</span>]<br />    }<br />  ]<br />}<br />EOF<br />}<br /><br /><span class="hljs-comment">// this policy is long but ensures the IAM user can run CDK and upload ECR images</span><br />resource <span class="hljs-string">&quot;aws_iam_user_policy&quot;</span> <span class="hljs-string">&quot;cdk_policy&quot;</span> {<br />  name = <span class="hljs-string">&quot;cdk_policy&quot;</span><br />  user = aws_iam_user.github_actions.name<br /><br />  <span class="hljs-comment">// ...</span><br />}<br /><br /><span class="hljs-comment">// make sure there&#x27;s an access key</span><br />resource <span class="hljs-string">&quot;aws_iam_access_key&quot;</span> <span class="hljs-string">&quot;github_actions&quot;</span> {<br />  user = aws_iam_user.github_actions.name<br />}<br /><br /><span class="hljs-comment">// when we run terraform apply, it&#x27;ll show the secret on the command line</span><br /><span class="hljs-comment">// which we can copy into Github Actions Secrets</span><br />output <span class="hljs-string">&quot;secret&quot;</span> {<br />  value = aws_iam_access_key.github_actions.secret<br />}</span></pre><p name="c835" id="c835" class="graf graf--p graf-after--pre">This code creates the S3 bucket for DVC, the IAM user for Github Actions, gives the IAM user appropriate permissions, and makes the access key so that Github Actions can “log in” to AWS.</p><p name="0fd6" id="0fd6" class="graf graf--p graf-after--p">One benefit of infrastructure as code is that we can ask experts to review it before we run it.</p><p name="ca33" id="ca33" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">New terms</strong></p><ul class="postList"><li name="1360" id="1360" class="graf graf--li graf-after--p"><a href="https://www.terraform.io/" data-href="https://www.terraform.io/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Terraform</a>: Terraform is a tool for infrastructure as code that works with many popular cloud providers.</li><li name="092f" id="092f" class="graf graf--li graf-after--li">AWS IAM policy: I’m not the best at explaining this, but it’s a list of permissions that can be attached to an IAM user or role.</li><li name="5505" id="5505" class="graf graf--li graf-after--li">AWS IAM role: This is like an IAM user but you can’t log in as it. It’s only there for services to use. If you’re a similar age as me, you might think of this as a service user with better security.</li></ul><h3 name="9650" id="9650" class="graf graf--h3 graf-after--li">What could possibly go wrong? A critique</h3><p name="14f7" id="14f7" class="graf graf--p graf-after--h3">It’s tough to review your own work, but I’ll give it a fair shot! I have three sections:</p><ol class="postList"><li name="0c79" id="0c79" class="graf graf--li graf-after--p">A review of <strong class="markup--strong markup--li-strong">general principles</strong></li><li name="dce0" id="dce0" class="graf graf--li graf-after--li">An overview of <strong class="markup--strong markup--li-strong">industry needs</strong> that weren’t otherwise mentioned</li><li name="62ae" id="62ae" class="graf graf--li graf-after--li">A discussion of <strong class="markup--strong markup--li-strong">priorities to fix</strong></li></ol><h4 name="003b" id="003b" class="graf graf--h4 graf-after--li">General principles</h4><p name="f77b" id="f77b" class="graf graf--p graf-after--h4"><strong class="markup--strong markup--p-strong">Does the service manage latency vs cost well?</strong></p><ul class="postList"><li name="16d8" id="16d8" class="graf graf--li graf-after--p">AWS Lambda scales up and down automatically, so if there’s a surge of users it’ll handle that and then scale down to save cost afterwards. It doesn’t require any special configuration to do this.</li><li name="35cf" id="35cf" class="graf graf--li graf-after--li">When Lambda scales up and warms up a new “instance”, it needs to download the Docker image and load the model. We call this a cold start. If the image and model are even moderately large, the API request will time out while it loads. This is especially bad in our repo because there are no active users, so it’ll sit at 0 concurrency until a request is made during testing, then time out while loading the model until there’s a warm Lambda.</li><li name="a3f1" id="a3f1" class="graf graf--li graf-after--li">On the topic of cost, Lambda will scale up as needed with incoming requests up until a region-wide concurrency limit. So someone could spam your API to scale up your Lambda and increase your AWS bill significantly.</li><li name="3dfe" id="3dfe" class="graf graf--li graf-after--li">The repo is implemented entirely in us-west-2. If the API is being called from around the world or even around the US, many users will have slow responses simply because they’re far away from the server. On the other hand, if it’s only called by servers or users near us-west-2 that’s fine.</li></ul><p name="1265" id="1265" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Is the service highly available?</strong></p><ul class="postList"><li name="97d8" id="97d8" class="graf graf--li graf-after--p">Due to cold starts, when the service deploys it causes a full outage until the new model is loaded. In a professional situation that’s unacceptable but may be acceptable for hobbyist work.</li><li name="ff20" id="ff20" class="graf graf--li graf-after--li">Can we quickly and safely revert if a bug makes it to production? Yes, in this repo we’d revert by merging a PR in Github. The deployment pipeline takes 4–5 minutes. It’ll probably take longer to get your PR approved.</li><li name="972a" id="972a" class="graf graf--li graf-after--li">Can we quickly detect production issues? No, there aren’t any alarms implemented in this repo so if it goes down we probably won’t find out right away. AWS provides some default dashboards for API gateway and Lambda though.</li><li name="0fd2" id="0fd2" class="graf graf--li graf-after--li">Can we switch to PyTorch without downtime? Yes, this repo is implemented so that we could make a major machine learning change like switching frameworks, test it, and deploy without downtime and with the ability to revert, so long as the framework change is a single PR.</li></ul><p name="5ed9" id="5ed9" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Is there any way that untested work might be deployed?</strong></p><p name="2af1" id="2af1" class="graf graf--p graf-after--p">There are several gaps in my testing:</p><ul class="postList"><li name="0c49" id="0c49" class="graf graf--li graf-after--p">The components between the API request and the Lambda are untested: The Docker packaging, the interaction between the Lambda code and API gateway, and the API gateway configuration. The Docker part could be tested easily by running the unit tests inside of Docker, though it’ll slow down testing a bit. The AWS configuration could be better tested by using <a href="https://aws.amazon.com/serverless/sam/" data-href="https://aws.amazon.com/serverless/sam/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">AWS SAM</a> to spin up a local version of the stack for testing. This issue also affects developer productivity, for example if a developer is changing the way that dependencies are packaged they may need to edit the Dockerfile and it’s best if they can test it on their computer.</li><li name="d4cc" id="d4cc" class="graf graf--li graf-after--li">Another gap is time-based: The dependencies for unit tests are installed at a different time than the dependencies for the Docker image. Because the dependencies aren’t fully pinned (see previous post for why), that means that in theory a new library version could be deployed between testing and deployment which could cause a production outage. One way to address this is to build the Docker image in the PR pipeline, use it for unit testing, then upload to ECR. That would also save time in deployment. Another alternative is to pin dependencies more.</li><li name="341a" id="341a" class="graf graf--li graf-after--li">In theory, someone could overwrite the model file in S3 and bypass our test automation, though it’d be annoying to do. If they did that it wouldn’t actually trigger a deployment though because it wouldn’t be a change in Github. It’d have to be the exact same file path on S3.</li></ul><p name="7518" id="7518" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Is it easy for new developers to learn?</strong></p><p name="6048" id="6048" class="graf graf--p graf-after--p">It’s tough to judge your own work for learnability. Whenever possible it’s better to have someone review the work and explain the challenges they faced.</p><ul class="postList"><li name="82eb" id="82eb" class="graf graf--li graf-after--p">In my opinion, this is hard for a complete beginner to learn because there are so many tools. Most of the complexity happens in automation, which the developer may not need to fully understand. But DVC for instance introduces a new concept — instead of just doing a <em class="markup--em markup--li-em">git clone</em> they also need to pull the DVC files to make the repo work. That could be improved with git hooks.</li><li name="e814" id="e814" class="graf graf--li graf-after--li">A related challenge with DVC is that it requires an AWS credential — now your devs need to have AWS setup to work in the repo, and you need to make sure that they have appropriate permissions to the S3 bucket.</li><li name="9c9a" id="9c9a" class="graf graf--li graf-after--li">For a developer with prior AWS experience, this might be easier to learn than a repo with many ML-specific tools or platforms.</li><li name="8732" id="8732" class="graf graf--li graf-after--li">Terraform adds another programming language and way of thinking. If I could do it again I’d try replacing that part with CDK so that devs don’t need to learn another infrastructure language.</li><li name="954f" id="954f" class="graf graf--li graf-after--li">API gateway and Lambda can be challenging to understand, and aren’t great technologies for junior developers in my experience.</li><li name="c024" id="c024" class="graf graf--li graf-after--li">The use of “dvc repro” might not be worth the effort to learn it.</li><li name="f33a" id="f33a" class="graf graf--li graf-after--li">Also in my opinion it’s not quite documented enough for a junior dev.</li><li name="16d7" id="16d7" class="graf graf--li graf-after--li">The parameters to the Lambda handler are hard to learn in my opinion, because there’s no autocomplete for the data structure. <a href="https://awslabs.github.io/aws-lambda-powertools-python/2.8.0/" data-href="https://awslabs.github.io/aws-lambda-powertools-python/2.8.0/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Lambda Powertools</a> can help with this, but adds another dependency.</li></ul><p name="3dc2" id="3dc2" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Will developers face significant toil while using this repo?</strong></p><p name="2b80" id="2b80" class="graf graf--p graf-after--p">While the previous subsection was about new developers, this is about the day to day experience of experienced developers.</p><ul class="postList"><li name="30d4" id="30d4" class="graf graf--li graf-after--p">Are there situations that might require multiple PRs across repos? Training, serving, and infrastructure are all in the same repo so major changes can be made in a single, well-tested PR. On the other hand, it’s likely that this code is being called by another repo that isn’t shown, and changes involving the JSON input shape, for example, may require PRs across repos.</li><li name="62f8" id="62f8" class="graf graf--li graf-after--li">Would this repo work nicely with security scanners such as <a href="https://github.blog/2020-06-01-keep-all-your-packages-up-to-date-with-dependabot/" data-href="https://github.blog/2020-06-01-keep-all-your-packages-up-to-date-with-dependabot/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">depandabot</a>? In the past I’ve had challenges in easily updating ML packages flagged by dependabot. With this repo setup it’s possible to configure dependabot to open PRs with new dependencies, build updated models, and test that they work in the service. If the PR passes we can simply merge it to update dependencies.</li><li name="1794" id="1794" class="graf graf--li graf-after--li">Although deployment takes 4–5 minutes, it’d be better if it took closer to 1 minute. Fortunately Github Actions gives us time tracking by stage so we can investigate further. For example, it takes a little over 1 minute just to install DVC and CDK every time. Running the CDK pipeline including the Docker build takes about 3 minutes.</li></ul><p name="5516" id="5516" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Any security concerns?</strong></p><p name="5e91" id="5e91" class="graf graf--p graf-after--p">I’m not a security professional but I’ve been involved in enough reviews to check for the basics.</p><ul class="postList"><li name="513d" id="513d" class="graf graf--li graf-after--p">IAM safety for the Lambda role? CDK automatically creates a minimal IAM role for us. Even if an attacker finds a way to run arbitrary code inside of our Lambda, the role doesn’t have permissions to actually do much.</li><li name="f3d6" id="f3d6" class="graf graf--li graf-after--li">IAM safety for the Github Actions user? This user has a fair amount of permissions and an attacker could do some harm if they had access. Github Actions Secrets are pretty secure though. The biggest typical problem is that I’d need to rotate the IAM credentials manually if they were leaked.</li><li name="f14f" id="f14f" class="graf graf--li graf-after--li">If you’re adapting this to work with sensitive training data, Github Actions might not be an option.</li><li name="b26e" id="b26e" class="graf graf--li graf-after--li">The API is completely open to the world. If the model is highly unique and valuable, you don’t want others to probe it indiscriminately. Auth and/or IP filtering can help.</li><li name="2b49" id="2b49" class="graf graf--li graf-after--li">pickle files allow arbitrary code execution. But to write those pickle files, someone would need write access to your S3 bucket and would need to trigger a redeploy from Github. Pickle files are an unlikely attack vector of choice in this system.</li><li name="ae86" id="ae86" class="graf graf--li graf-after--li">If there are vulnerabilities in the Docker image, it won’t be updated until the next deployment. This is one disadvantage of using Docker for lambda — we’re the ones managing these system dependencies rather than AWS managing them like they do for zip-file lambdas.</li></ul><h4 name="c3e6" id="c3e6" class="graf graf--h4 graf-after--li">Concerns in an actual company</h4><p name="e97e" id="e97e" class="graf graf--p graf-after--h4">If you’re building a system professionally, this repo isn’t enough of a template. This is a list of considerations I had in industry:</p><ul class="postList"><li name="5c37" id="5c37" class="graf graf--li graf-after--p">Endpoint security (auth, secret management, IP restrictions, etc)</li><li name="8d3c" id="8d3c" class="graf graf--li graf-after--li">Endpoint stability (DNS)</li><li name="4591" id="4591" class="graf graf--li graf-after--li">Endpoint versioning — If the input or output data structure will change in a way that isn’t backwards-compatible, you may need to support multiple data structures and have a version of the endpoint itself.</li><li name="5e18" id="5e18" class="graf graf--li graf-after--li">CORS when it’s being integrated with a frontend served from a different domain, and also latency optimization relating to CORS</li><li name="e2f6" id="e2f6" class="graf graf--li graf-after--li">Private PyPI inside Docker, if you use any internal modules</li><li name="b1bb" id="b1bb" class="graf graf--li graf-after--li">Multiple deployment stages: dev, staging, prod</li><li name="3f9f" id="3f9f" class="graf graf--li graf-after--li">Integration testing, end-to-end testing, and unit testing for any business logic</li><li name="06d2" id="06d2" class="graf graf--li graf-after--li">Provisioned concurrency, setup to warm up Lambda <em class="markup--em markup--li-em">before</em> the API gateway switches to the new version so that we have zero downtime</li><li name="508b" id="508b" class="graf graf--li graf-after--li">Dashboards and alarms</li><li name="ab1f" id="ab1f" class="graf graf--li graf-after--li">Training data versioning, data updates, and data testing — If you’re getting new data over time there’s a need for a whole pipeline before training.</li></ul><p name="d74b" id="d74b" class="graf graf--p graf-after--li">Now that I’m thinking about the business, it’s a good time to mention the big picture. When you’re writing an API it’s a piece of a larger system. I’ve seen significant harm caused by focusing too much on just one repo and too little on the code that calls the API. For example, we could change our API without telling anyone and it may bring down our product.</p><p name="751f" id="751f" class="graf graf--p graf-after--p">Likewise, it’s good to consider the experience of the developers using our API, such as whether it’s easy to learn and use. Others have covered the topic of developer experience for APIs better than I can:</p><ul class="postList"><li name="a26b" id="a26b" class="graf graf--li graf-after--p"><a href="https://blog.developer.adobe.com/ask-a-devexpert-what-makes-a-good-api-93fc74d83428" data-href="https://blog.developer.adobe.com/ask-a-devexpert-what-makes-a-good-api-93fc74d83428" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Ask a DevExpert: What Makes a Good API? (Adobe, 2018)</a></li><li name="2d1c" id="2d1c" class="graf graf--li graf-after--li"><a href="https://swagger.io/resources/articles/best-practices-in-api-design/" data-href="https://swagger.io/resources/articles/best-practices-in-api-design/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Best Practices in API Design</a> (Swagger)</li><li name="90c6" id="90c6" class="graf graf--li graf-after--li"><a href="https://nordicapis.com/5-examples-of-api-documentation-with-great-developer-experience/" data-href="https://nordicapis.com/5-examples-of-api-documentation-with-great-developer-experience/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">5 Examples of API Documentation With Great Developer Experience (Nordic APIs, 2022)</a></li><li name="52d3" id="52d3" class="graf graf--li graf-after--li"><a href="https://github.com/workos/awesome-developer-experience" data-href="https://github.com/workos/awesome-developer-experience" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Awesome Developer Experience</a></li></ul><p name="4973" id="4973" class="graf graf--p graf-after--li">If you’re deploying the service into the same AWS account as other services, there are some additional considerations:</p><ul class="postList"><li name="113c" id="113c" class="graf graf--li graf-after--p">Is the service named and tagged so that you can audit your AWS bill easily? I’d suggest at least tagging all resources with the team that produced them.</li><li name="b402" id="b402" class="graf graf--li graf-after--li">If you don’t have Lambda concurrency limits, keep in mind that all Lambdas in the same account and region share a concurrency limit. So if your Lambda is using 999 concurrency and the limit is 1000, only 1 other Lambda in the company can be running at a time and others will be throttled. (I say this from a real experience of production Lambdas being throttled due to a logging service eating up our concurrency.)</li></ul><h4 name="bfa0" id="bfa0" class="graf graf--h4 graf-after--li">Priorities to fix</h4><p name="1eee" id="1eee" class="graf graf--p graf-after--h4">I covered a lot of problems with this example repo. In industry we often can’t fix everything we want to, at least not right away. So we have to prioritize what to improve first.</p><p name="f6fb" id="f6fb" class="graf graf--p graf-after--p">Prioritization should be guided by the business needs, user needs, and how your service is integrated into the product. If this were a mission-critical service dealing with private data, that’s very different than a nice-to-have service that can’t bring down the product. If it’s an API used by external developers that’s very different than an internal API. If it’s a service that supports 100,000 requests per hour that’s different than 100 requests per hour. And so on.</p><p name="4ee4" id="4ee4" class="graf graf--p graf-after--p">The following is an example prioritization that might make sense for a small startup:</p><p name="5309" id="5309" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">High priorities</strong></p><ul class="postList"><li name="b148" id="b148" class="graf graf--li graf-after--p">A domain name, so that we don’t accidentally cause an outage when we change API gateway</li><li name="c4c1" id="c4c1" class="graf graf--li graf-after--li">Provisioned concurrency so that there’s less downtime when deploying updates</li><li name="902f" id="902f" class="graf graf--li graf-after--li">Talk to the people integrating the API if it’s not you!</li><li name="b558" id="b558" class="graf graf--li graf-after--li">Any required compliance</li></ul><p name="d76f" id="d76f" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Medium priorities</strong></p><ul class="postList"><li name="e362" id="e362" class="graf graf--li graf-after--p">IP filtering, auth, and/or your security of choice — This could range high to low depending on the application though</li><li name="a666" id="a666" class="graf graf--li graf-after--li">Alarms for outages — This could range high to low depending on the application</li><li name="dcb1" id="dcb1" class="graf graf--li graf-after--li">True zero-downtime deployments</li></ul><p name="d883" id="d883" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Low priorities</strong></p><ul class="postList"><li name="9d54" id="9d54" class="graf graf--li graf-after--p graf--trailing">Everything else</li></ul></div></div></section><section name="80c1" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="38a1" id="38a1" class="graf graf--h3 graf--leading">Alternatives</h3><p name="03da" id="03da" class="graf graf--p graf-after--h3">I also tried a few alternatives and I’ll briefly mention what I found.</p><h4 name="5621" id="5621" class="graf graf--h4 graf-after--p"><a href="https://github.com/ktrnka/mlops_example_ecs" data-href="https://github.com/ktrnka/mlops_example_ecs" class="markup--anchor markup--h4-anchor" rel="noopener" target="_blank">Deploy to AWS ECS</a></h4><p name="dc3c" id="dc3c" class="graf graf--p graf-after--h4">AWS Elastic Container Service (ECS) is a better option than Lambda for most people. It’s always on, so you don’t need to worry about the time it takes to load your model when booting. The disadvantage of ECS is that it’s tricky to get autoscaling setup right and it can be more expensive.</p><h4 name="a415" id="a415" class="graf graf--h4 graf-after--p"><a href="https://github.com/ktrnka/mlops_example_cortex" data-href="https://github.com/ktrnka/mlops_example_cortex" class="markup--anchor markup--h4-anchor" rel="noopener" target="_blank">Deploy with Cortex.dev</a></h4><p name="8285" id="8285" class="graf graf--p graf-after--h4">I found <a href="https://www.cortex.dev/" data-href="https://www.cortex.dev/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Cortex.dev</a> to be delightfully fast and easy. The deployment itself was much faster than anything else, and not much more complex than Heroku. I remember thinking at the time my security team might not like some aspects of the deployment though.</p><h4 name="9883" id="9883" class="graf graf--h4 graf-after--p"><a href="https://github.com/ktrnka/mlops_example_github_lfs_heroku" data-href="https://github.com/ktrnka/mlops_example_github_lfs_heroku" class="markup--anchor markup--h4-anchor" rel="noopener" target="_blank">Model versioning with git-lfs on Github</a></h4><p name="be84" id="be84" class="graf graf--p graf-after--h4">I started off using git-lfs for model versioning and Heroku free tier for deployment. I was curious to use Github as the git-lfs provider after struggling with an alternative at work.</p><p name="b8ef" id="b8ef" class="graf graf--p graf-after--p">Well, I learned why we didn’t use Github’s git-lfs! When you hit the LFS quota your repo is locked until you buy more quota or delete the repo. Last I checked, Github doesn’t have a way to automatically increase your quota so you’re relying on people manually upgrading on the website periodically.</p><h3 name="bb28" id="bb28" class="graf graf--h3 graf-after--p">Things I didn’t get to</h3><p name="2cc6" id="2cc6" class="graf graf--p graf-after--h3">There are so many MLOps tools these days! For each library, tool, or platform I used, there are dozens of alternatives. I’ve heard good things about kubeflow for instance and it might be a good time to re-evaluate Sagemaker.</p><p name="d85d" id="d85d" class="graf graf--p graf-after--p">I’ve also seen some people deploy models with code using Python packaging. That seems like a nice way to package code, data, and dependencies together.</p><h3 name="457d" id="457d" class="graf graf--h3 graf-after--p">Conclusions</h3><p name="fc8d" id="fc8d" class="graf graf--p graf-after--h3">I hope I was able to clarify common concepts in machine learning web services!</p><p name="16cb" id="16cb" class="graf graf--p graf-after--p">Although I used AWS Lambda in this example, it was mainly due to curiosity. Please don’t interpret this post as an endorsement of Lambda for machine learning services. Whether Lambda is a good option will depend on your needs.</p><p name="b320" id="b320" class="graf graf--p graf-after--p graf--trailing">Also keep in mind this might serve as a guide for a small startup but I doubt it’s ready for operating at a larger scale. And I surely left out some parts of typical MLOps work, such as support for experimentation.</p></div></div></section><section name="69d8" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="45dd" id="45dd" class="graf graf--p graf--leading graf--trailing">Thanks for reading! If there were parts of the article you found confusing, please let me know.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@keith.trnka" class="p-author h-card">Keith Trnka</a> on <a href="https://medium.com/p/90c7bd275f53"><time class="dt-published" datetime="2023-02-27T13:49:10.427Z">February 27, 2023</time></a>.</p><p><a href="https://medium.com/@keith.trnka/mlops-repo-walkthrough-90c7bd275f53" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on February 18, 2026.</p></footer></article></body></html>