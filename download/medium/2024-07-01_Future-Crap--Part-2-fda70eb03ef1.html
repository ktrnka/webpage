<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Future Crap, Part 2</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Future Crap, Part 2</h1>
</header>
<section data-field="subtitle" class="p-summary">
Building brand-injection for generative AI
</section>
<section data-field="body" class="e-content">
<section name="bbd5" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="d8fc" id="d8fc" class="graf graf--h3 graf--leading graf--title">Future Crap, Part 2</h3><h4 name="2191" id="2191" class="graf graf--h4 graf-after--h3 graf--subtitle">Building brand-injection for generative AI</h4><p name="a501" id="a501" class="graf graf--p graf-after--h4"><em class="markup--em markup--p-em">If you’re looking for example output, start with </em><a href="https://medium.com/@keith.trnka/future-crap-part-1-373e607aef51" data-href="https://medium.com/@keith.trnka/future-crap-part-1-373e607aef51" class="markup--anchor markup--p-anchor" target="_blank"><em class="markup--em markup--p-em">Part 1</em></a><em class="markup--em markup--p-em">. This post is the “how it’s made” portion.</em></p><figure name="49c9" id="49c9" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*7K-ATjwTiLCWReA-cS4m4Q.png" data-width="1024" data-height="1024" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*7K-ATjwTiLCWReA-cS4m4Q.png"></figure><h3 name="9ab6" id="9ab6" class="graf graf--h3 graf-after--figure">Origin story</h3><p name="c843" id="c843" class="graf graf--p graf-after--h3">This effort was a mixture of curiosity and satire.</p><p name="9db2" id="9db2" class="graf graf--p graf-after--p">A couple years ago I was mulling over ideas to augment Giphy memes with GenAI memes and ways to pay the server bills. Recently I had more free time after a layoff and wanted some practice with retrieval-augmented generation.</p><p name="25e6" id="25e6" class="graf graf--p graf-after--p">I have some satirical motivation here as well: many companies build innovative technology, then refine it into a productive application, then users flock to it, and once they’re entrenched they <a href="https://en.wikipedia.org/wiki/Enshittification" data-href="https://en.wikipedia.org/wiki/Enshittification" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">enshittify</a> the technology often by putting more and more ads into it. It gets to the point where the products are barely worth the hassle.</p><p name="04c3" id="04c3" class="graf graf--p graf-after--p">Another thing on my mind is why ChatGPT is sometimes better than Google. They often have very similar results, but ChatGPT doesn’t force me through tons of ads and accept-cookies popups.</p><h3 name="9806" id="9806" class="graf graf--h3 graf-after--p">How it works</h3><p name="a8f0" id="a8f0" class="graf graf--p graf-after--h3">I made Future Crap available to some friends in our shared Slack channel.</p><p name="85ff" id="85ff" class="graf graf--p graf-after--p">When a user types the command <code class="markup--code markup--p-code">/futurecrap</code> followed by a description such as &quot;a photorealistic cat and dog in an intense staring contest in the office,&quot; the request is forwarded over a socket to the backend server (assuming it&#39;s online). The backend then searches for brand matches using the prompt as the query in an in-memory vector database. This search matches the prompt against brand descriptions such as &quot;… is a fast-food restaurant chain known for its fried chicken, sides, and sandwiches, targeting families, individuals, and chicken enthusiasts seeking flavorful and convenient dining options …&quot;. Among the top three closest brand matches, a random selection is made with a preference for higher match scores.</p><p name="91bf" id="91bf" class="graf graf--p graf-after--p">Next, the backend randomly selects the image generation service, either OpenAI DALL-E 3 or AWS Titan. The prompt is then augmented in one of two ways depending on the brand. In both cases, we’re using the ChatGPT API with examples of good and bad brand-injection to do few-shot learning. Also note that DALL-E and Titan perform better with different types of prompts, so we’re using different meta-prompts for each to customized to each image generation engine.</p><p name="4054" id="4054" class="graf graf--p graf-after--p">For most brands, the inputs are the original prompt and the brand name. If the brand data has a <code class="markup--code markup--p-code">brand_style</code> field, the inputs include the original prompt and a visual description of the brand. This approach is good for brands that are not prominent in the training data of the image generator. In my testing I found this critical for Boss Coffee, Rainier Beer, Mt. Joy (a Seattle food truck), Olympia Coffee, Blockbuster, and a few others.</p><p name="3688" id="3688" class="graf graf--p graf-after--p">Once the prompt is augmented with the brand information, it is sent to the selected image generation backend. The generated image is then uploaded to S3. A Slack message containing the image URL and other metadata is sent back over the Slack socket. Finally, the Slack servers post this information into the channel data, making the image visible to the users in the channel.</p><p name="2566" id="2566" class="graf graf--p graf-after--p">If you’re looking in the repo, there’s also a web frontend that I use for local development.</p><h4 name="5778" id="5778" class="graf graf--h4 graf-after--p">About the brand data</h4><p name="4120" id="4120" class="graf graf--p graf-after--h4">The brand data was built by hand using ChatGPT/Copilot and <a href="https://imagetoprompt.com/" data-href="https://imagetoprompt.com/" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">ImageToPrompt</a>. It took a number of iterations and still needs improvement.</p><p name="dff2" id="dff2" class="graf graf--p graf-after--p">This is a rough outline of how I iterated:</p><ol class="postList"><li name="1a3c" id="1a3c" class="graf graf--li graf-after--p">I started with a list of brands that I remembered from commercials or ads. For example, Pepsi and Nike are famous for marketing.</li><li name="15e0" id="15e0" class="graf graf--li graf-after--li">I used ChatGPT to generate a description of the target demographic and used that for brand matching.</li><li name="9308" id="9308" class="graf graf--li graf-after--li">I expanded the list of brands by chatting with friends and reviewing the S&amp;P 500 for companies I thought had recognizable branding.</li><li name="6035" id="6035" class="graf graf--li graf-after--li">I saw that it sometimes matched in a way that didn’t make any sense for the scene, so I used ChatGPT to generate the <code class="markup--code markup--li-code">brand_identity</code> field after giving some examples. That was intended to capture the general vibe of each brand’s ads rather than the target demographic.</li><li name="de04" id="de04" class="graf graf--li graf-after--li">I had a failed experiment in which I generated example ads to use for matching. The examples were good but it was slow to generate so I didn’t explore it further.</li><li name="f970" id="f970" class="graf graf--li graf-after--li">I saw that it didn’t work for less well-known brands (like Boss Coffee) and it couldn’t possibly work for new, local brands (like Mt. Joy) so I tried searching for their icons, fed those into ImageToPrompt, and then added that as a field in the brand data <code class="markup--code markup--li-code">brand_style</code>. Then if that field was present, I had the prompt generator use a different metaprompt to do the prompt augmentation from the visual description.</li><li name="9e27" id="9e27" class="graf graf--li graf-after--li">I expanded for a while with ImageToPrompt but it was going slowly so I used Copilot in VSCode to add <code class="markup--code markup--li-code">brand_style</code> for many other brands. I found that I often had to nudge it to be specific about the color scheme and font style. Though once in a while I needed to write the whole thing myself.</li></ol><h3 name="5334" id="5334" class="graf graf--h3 graf-after--li">Successes</h3><p name="5e92" id="5e92" class="graf graf--p graf-after--h3">Initially I used a simple template like “{prompt}. Include product placement from {company_name}”. That sometimes worked in DALL-E, almost never worked in Titan, and it wasn’t very reliable overall.</p><p name="c83c" id="c83c" class="graf graf--p graf-after--p">I had success in using GPT to convert an input prompt into a brand-injected prompt and tuning it for each image generator. This was great because the users didn’t need to adapt for DALL-E 3 vs Titan and GPT handled it for them. It also unlocked an easy way to optimize: I could take the good image generation prompts, hand-optimize them further, then use them as examples for few-shot learning in the metaprompt. This was great though I should’ve iterated more on how to do the few-shot prompt.</p><p name="851f" id="851f" class="graf graf--p graf-after--p">Here’s an example of what I mean by a metaprompt for AWS Titan:</p><blockquote name="3a44" id="3a44" class="graf graf--blockquote graf-after--p">Your task is to modify an image generation prompt to include brand marketing. The output prompt should be relatively short and to the point about the key details with prominent brand marketing. Here are some examples of inputs and varying quality outputs.</blockquote><blockquote name="4e6d" id="4e6d" class="graf graf--blockquote graf-after--blockquote">Input prompt: a cartoon family of scorpions walking to school in the morning. The smallest scorpion has a cute backpack and lunch box</blockquote><blockquote name="2ed1" id="2ed1" class="graf graf--blockquote graf-after--blockquote">Input brand: McDonald’s</blockquote><blockquote name="603d" id="603d" class="graf graf--blockquote graf-after--blockquote">Good output: Illustrate a charming cartoon family of realistic-looking scorpions walking to school in the morning. The youngest scorpion is wearing a cute backpack with the iconic McDonald’s red and yellow colors and carrying a matching lunchbox from its stinger. A McDonald’s billboard is shown prominently in the background.</blockquote><blockquote name="ef93" id="ef93" class="graf graf--blockquote graf-after--blockquote">…</blockquote><blockquote name="b12f" id="b12f" class="graf graf--blockquote graf-after--blockquote">Now you’ll be provided an input prompt and brand and you will modify the prompt to prominently feature the brand in the scene. Only respond with the modified prompt.</blockquote><blockquote name="88b8" id="88b8" class="graf graf--blockquote graf-after--blockquote">Input prompt: {prompt}</blockquote><blockquote name="ede3" id="ede3" class="graf graf--blockquote graf-after--blockquote">Input brand: {brand_name}</blockquote><blockquote name="9c68" id="9c68" class="graf graf--blockquote graf-after--blockquote">Excellent output (use up to 125 tokens in the output):</blockquote><p name="b117" id="b117" class="graf graf--p graf-after--blockquote">The “good output” vs “excellent output” vs “mediocre output” distinctions was an idea to get a little more value out of additional supervision, but I didn’t explore it thoroughly so I don’t know if it helped.</p><p name="0a9f" id="0a9f" class="graf graf--p graf-after--p">For smaller brands, I found that I could use image2prompt to generate a description of the visual style of brands that DALL-E and Titan couldn’t support natively. That’s how I was able to even use brands like Mt. Joy, a Seattle food truck. Though it couldn’t perfectly recreate their logo. This style of generation worked especially well when I made sure that the “brand style” field included description of not just the logo but also the color scheme and any font styles.</p><p name="499c" id="499c" class="graf graf--p graf-after--p">Here’s an example of a brand-injected prompt with a smaller brand from the visual description, targeted at DALL-E 3:</p><blockquote name="794f" id="794f" class="graf graf--blockquote graf-after--p"><strong class="markup--strong markup--blockquote-strong">Original prompt:</strong> three college-aged people just got their chicken sandwiches from a food truck. They all have sandwiches in both hands and they’re happy about it</blockquote><blockquote name="8bf5" id="8bf5" class="graf graf--blockquote graf-after--blockquote"><strong class="markup--strong markup--blockquote-strong">Brand-injected prompt:</strong> Capture the joyous moment of three college-aged individuals receiving their delicious chicken sandwiches from a vibrant food truck. Each person is holding two sandwiches in their hands, showcasing their excitement. The background prominently features a green geometric logo with a floral pattern on the left side, and the text “Mt. Joy” in bold green letters on the right, all set against a clean white backdrop. The scene exudes happiness and youthful energy, perfectly encapsulating the spirit of Mt. Joy’s brand. Please take extra care to show Mt. Joy branding very prominently.</blockquote><p name="49c3" id="49c3" class="graf graf--p graf-after--blockquote">I included randomization in the Slack demo to provide a more dynamic experience for users, for example randomizing the brand matching by match score. That addressed a previous issue in which Domino’s would be used for too many ads even though it had a similar score to other brands. Likewise I randomized between DALL-E 3 and Titan to provide variety. If I had more time I would’ve built a routing layer like <a href="https://unify.ai/" data-href="https://unify.ai/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Unify.ai</a> to pick the best engine for each prompt. That said, in the web demo I disabled randomization to provide more predictability during development.</p><p name="81df" id="81df" class="graf graf--p graf-after--p">I’ll mention a couple quick engineering wins too:</p><ul class="postList"><li name="d950" id="d950" class="graf graf--li graf-after--p">Slack Bolt with sockets was a great way to prototype; I just ran it from my laptop and could iterate very rapidly instead of needing to do a whole deployment to update.</li><li name="203c" id="203c" class="graf graf--li graf-after--li">txtai was great for easy in-memory vector search.</li></ul><h3 name="8e42" id="8e42" class="graf graf--h3 graf-after--li">Challenges</h3><ul class="postList"><li name="5e49" id="5e49" class="graf graf--li graf-after--h3">DALL-E 3 API tends to remove brand info. From trial and error I learned that Microsoft Image Creator doesn’t have this problem even though it’s also using DALL-E 3. I didn’t find any tips for the DALL-E 3 API that gave results like Image Creator.</li><li name="d3ba" id="d3ba" class="graf graf--li graf-after--li">Titan rejects some prompts based on their content filter, though it’s tough to know when that’ll happen.</li><li name="6148" id="6148" class="graf graf--li graf-after--li">DALL-E 3 and Titan are trained on very different sorts of inputs. The ideal input for DALL-E 3 is long and descriptive, and can be up to 4000 chars. The ideal input for Titan is short and caption-like, and can be up to 512 chars.</li><li name="7de6" id="7de6" class="graf graf--li graf-after--li">Evaluation is subjective and tough. Maybe I should’ve tried gpt4o as judge? I had originally planned to use Slack emoji reactions for judging but I didn’t have enough in-Slack data for it to be useful.</li></ul><h3 name="2b01" id="2b01" class="graf graf--h3 graf-after--li">Should’ve</h3><p name="3501" id="3501" class="graf graf--p graf-after--h3">I wish I’d worked on evaluation earlier in development. I procrastinated about it because I didn’t like the idea of paying $1 of API fees for every little test. In retrospect, I should’ve started with a local image generation model from HuggingFace and iterated on that in an evaluation framework before iterating with the cloud API models.</p><p name="f14a" id="f14a" class="graf graf--p graf-after--p">In some of the generated images I suspected it might be simply copying an existing image, so I sometimes reverse image searched the results. I wish I’d built it into the application so that I could check more often though.</p><h3 name="3c46" id="3c46" class="graf graf--h3 graf-after--p">Could this be a real industry project?</h3><p name="c63c" id="c63c" class="graf graf--p graf-after--h3">To subsidize meme generation? It’s unlikely to work with current technology. I cherry-picked examples and I’d guess that I showed you the best 20%. Maybe it could work if you over-generate examples then use a multimodal model as a judge to select the branded ones. You might also need to cache responses to save costs. Even then, would REI be willing to spend real money if we misspell their name?</p><p name="807d" id="807d" class="graf graf--p graf-after--p">Could it succeed as a product to subsidize general-purpose image generation? I don’t think enough people are using image generation today to recoup the development cost. If I think back to the early days of Google and Youtube, they started off by building a great product with a large user base before scaling up their advertising. General image generation isn’t at that scale yet, and might never get there.</p><p name="f18b" id="f18b" class="graf graf--p graf-after--p">Also a real version of this might need:</p><ul class="postList"><li name="efee" id="efee" class="graf graf--li graf-after--p">Need an image generator that’s DALL-E 3 quality but more reliable at branding (OpenAI and Microsoft have this, maybe others do too?)</li><li name="b21a" id="b21a" class="graf graf--li graf-after--li">Need to provide advertisers with control over their brand, like what types of prompts get their branding. I’m doubtful that just providing advertisers with a text field would be enough on its own.</li><li name="8b3c" id="8b3c" class="graf graf--li graf-after--li">Need to deal with prompts that aren’t monetizable, similar to how YouTube demonetizes certain content</li><li name="bb09" id="bb09" class="graf graf--li graf-after--li">Companies often want to advertise a particular product not just their overall brand so it’d need a much more extensive database not just of brands but their products along with data on how to target each one.</li></ul><p name="bc5e" id="bc5e" class="graf graf--p graf-after--li">I can imagine a Giphy-like product succeeding sometime in the future but probably not now. Alternatively if someone creates a “killer app” for ordinary consumers in the GenAI space, I imagine someone will try to include ads eventually. It wouldn’t surprise me if someone tries it with ChatGPT but the thought is too unsettling for me to prototype.</p><h3 name="0e65" id="0e65" class="graf graf--h3 graf-after--p">The End</h3><p name="2049" id="2049" class="graf graf--p graf-after--h3">Thanks for reading, and thanks again to Matt, Matt, and Mark for participating!</p><h3 name="70a9" id="70a9" class="graf graf--h3 graf-after--p">Links</h3><ul class="postList"><li name="8d30" id="8d30" class="graf graf--li graf-after--h3"><a href="https://github.com/ktrnka/branded-image-gen-service" data-href="https://github.com/ktrnka/branded-image-gen-service" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">The code</a></li><li name="b6a2" id="b6a2" class="graf graf--li graf-after--li graf--trailing"><a href="https://drive.google.com/file/d/1-X2lDPDhcH6zjt7o5XpqxLk6aViH-MAJ/view?usp=sharing" data-href="https://drive.google.com/file/d/1-X2lDPDhcH6zjt7o5XpqxLk6aViH-MAJ/view?usp=sharing" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Dump of the generated images and SQLite DB containing prompts/settings</a> (350mb): This is a dump of my local folders, which has all the local testing I did and most of the Slackbot results. Take a look over the code for the table/column names. The images are all plain files, but I goofed by saving the DALL-E ones as PNG instead of JPG so the download is bigger than I’d like.</li></ul></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@keith.trnka" class="p-author h-card">Keith Trnka</a> on <a href="https://medium.com/p/fda70eb03ef1"><time class="dt-published" datetime="2024-07-01T14:06:02.089Z">July 1, 2024</time></a>.</p><p><a href="https://medium.com/@keith.trnka/future-crap-part-2-fda70eb03ef1" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on February 18, 2026.</p></footer></article></body></html>